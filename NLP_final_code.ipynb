{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10591262-8755-4739-ba03-cdb5beb6eb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting librosa\n",
      "  Obtaining dependency information for librosa from https://files.pythonhosted.org/packages/74/d4/cd10c82398f3b39bbf60a300e09c931bdf6844f3f2fba9ab2b5981501f9f/librosa-0.10.2-py3-none-any.whl.metadata\n",
      "  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Obtaining dependency information for audioread>=2.1.9 from https://files.pythonhosted.org/packages/57/8d/30aa32745af16af0a9a650115fbe81bde7c610ed5c21b381fca0196f3a7f/audioread-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.59.0)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Obtaining dependency information for soundfile>=0.12.1 from https://files.pythonhosted.org/packages/50/ff/26a4ee48d0b66625a4e4028a055b9f25bc9d7c7b2d17d21a45137621a50d/soundfile-0.12.1-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Obtaining dependency information for pooch>=1.1 from https://files.pythonhosted.org/packages/f4/72/8ae0f1ba4ce6a4f6d4d01a60a9fdf690fde188c45c1872b0b4ddb0607ace/pooch-1.8.1-py3-none-any.whl.metadata\n",
      "  Downloading pooch-1.8.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Obtaining dependency information for soxr>=0.3.2 from https://files.pythonhosted.org/packages/0d/95/8398287a3a00d006ebbe5fcada88bb2536acde2beecce892ff091e1c1a3b/soxr-0.3.7-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading soxr-0.3.7-cp311-cp311-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chinmay\\appdata\\roaming\\python\\python311\\site-packages (from pooch>=1.1->librosa) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
      "Downloading librosa-0.10.2-py3-none-any.whl (260 kB)\n",
      "   ---------------------------------------- 0.0/260.0 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 112.6/260.0 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 260.0/260.0 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading pooch-1.8.1-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/63.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.0/63.0 kB ? eta 0:00:00\n",
      "Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.2/1.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.3/1.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.5/1.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.6/1.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 0.9/1.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading soxr-0.3.7-cp311-cp311-win_amd64.whl (184 kB)\n",
      "   ---------------------------------------- 0.0/184.7 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 122.9/184.7 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 184.7/184.7 kB 5.5 MB/s eta 0:00:00\n",
      "Installing collected packages: soxr, audioread, soundfile, pooch, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.10.2 pooch-1.8.1 soundfile-0.12.1 soxr-0.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a65ce15f-22f4-4a04-ba7c-aa797b00771b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyworld\n",
      "  Obtaining dependency information for pyworld from https://files.pythonhosted.org/packages/b7/57/383c3f32da87f41d2d1bab739e2926a3c7accde71f006d64486d2d5064de/pyworld-0.3.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pyworld-0.3.4-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from pyworld) (1.26.4)\n",
      "Collecting cython>=0.24 (from pyworld)\n",
      "  Obtaining dependency information for cython>=0.24 from https://files.pythonhosted.org/packages/18/ec/f47a721071d084d6c2b6783eb8d058b964b1450cb708d920d0d792f42001/Cython-3.0.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading Cython-3.0.10-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Downloading pyworld-0.3.4-cp311-cp311-win_amd64.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.0 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 71.7/226.0 kB 1.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 122.9/226.0 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 184.3/226.0 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 226.0/226.0 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading Cython-3.0.10-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/2.8 MB 3.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.3/2.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.4/2.8 MB 3.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.6/2.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.0/2.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.1/2.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.3/2.8 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.5/2.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.6/2.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.8/2.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.0/2.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.8 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.3/2.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.5/2.8 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.7/2.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: cython, pyworld\n",
      "Successfully installed cython-3.0.10 pyworld-0.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts cygdb.exe, cython.exe and cythonize.exe are installed in 'C:\\Users\\chinmay\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59d6593-b3fc-4d12-b56c-7e5ef698a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pyworld\n",
    "from pprint import pprint\n",
    "import librosa.display\n",
    "import time\n",
    "import argparse\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import preprocess\n",
    "from trainingDataset import trainingDataset\n",
    "from model_tf import Generator, Discriminator\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5764ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wavs(wav_dir, sr):\n",
    "    wavs = list()\n",
    "    for file in os.listdir(wav_dir):\n",
    "        file_path = os.path.join(wav_dir, file)\n",
    "        wav, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "        # wav = wav.astype(np.float64)\n",
    "        wavs.append(wav)\n",
    "    return wavs\n",
    "\n",
    "\n",
    "def world_decompose(wav, fs, frame_period=5.0):\n",
    "    # Decompose speech signal into f0, spectral envelope and aperiodicity using WORLD\n",
    "    wav = wav.astype(np.float64)\n",
    "    f0, timeaxis = pyworld.harvest(\n",
    "        wav, fs, frame_period=frame_period, f0_floor=71.0, f0_ceil=800.0)\n",
    "\n",
    "    # Finding Spectogram\n",
    "    sp = pyworld.cheaptrick(wav, f0, timeaxis, fs)\n",
    "\n",
    "    # Finding aperiodicity\n",
    "    ap = pyworld.d4c(wav, f0, timeaxis, fs)\n",
    "\n",
    "    # Use this in Ipython to see plot\n",
    "    # librosa.display.specshow(np.log(sp).T,\n",
    "    #                          sr=fs,\n",
    "    #                          hop_length=int(0.001 * fs * frame_period),\n",
    "    #                          x_axis=\"time\",\n",
    "    #                          y_axis=\"linear\",\n",
    "    #                          cmap=\"magma\")\n",
    "    # colorbar()\n",
    "    return f0, timeaxis, sp, ap\n",
    "\n",
    "\n",
    "def world_encode_spectral_envelop(sp, fs, dim=24):\n",
    "    # Get Mel-Cepstral coefficients (MCEPs)\n",
    "    # sp = sp.astype(np.float64)\n",
    "    coded_sp = pyworld.code_spectral_envelope(sp, fs, dim)\n",
    "    return coded_sp\n",
    "\n",
    "\n",
    "def world_encode_data(wave, fs, frame_period=5.0, coded_dim=24):\n",
    "    f0s = list()\n",
    "    timeaxes = list()\n",
    "    sps = list()\n",
    "    aps = list()\n",
    "    coded_sps = list()\n",
    "    for wav in wave:\n",
    "        f0, timeaxis, sp, ap = world_decompose(wav=wav,\n",
    "                                               fs=fs,\n",
    "                                               frame_period=frame_period)\n",
    "        coded_sp = world_encode_spectral_envelop(sp=sp, fs=fs, dim=coded_dim)\n",
    "        f0s.append(f0)\n",
    "        timeaxes.append(timeaxis)\n",
    "        sps.append(sp)\n",
    "        aps.append(ap)\n",
    "        coded_sps.append(coded_sp)\n",
    "    return f0s, timeaxes, sps, aps, coded_sps\n",
    "\n",
    "\n",
    "def logf0_statistics(f0s):\n",
    "    # Note: np.ma.log() calculating log on masked array (for incomplete or invalid entries in array)\n",
    "    log_f0s_concatenated = np.ma.log(np.concatenate(f0s))\n",
    "    log_f0s_mean = log_f0s_concatenated.mean()\n",
    "    log_f0s_std = log_f0s_concatenated.std()\n",
    "    return log_f0s_mean, log_f0s_std\n",
    "\n",
    "\n",
    "def transpose_in_list(lst):\n",
    "    transposed_lst = list()\n",
    "    for array in lst:\n",
    "        transposed_lst.append(array.T)\n",
    "    return transposed_lst\n",
    "\n",
    "\n",
    "def coded_sps_normalization_fit_transform(coded_sps):\n",
    "    coded_sps_concatenated = np.concatenate(coded_sps, axis=1)\n",
    "    coded_sps_mean = np.mean(coded_sps_concatenated, axis=1, keepdims=True)\n",
    "    coded_sps_std = np.std(coded_sps_concatenated, axis=1, keepdims=True)\n",
    "    coded_sps_normalized = list()\n",
    "    for coded_sp in coded_sps:\n",
    "        coded_sps_normalized.append(\n",
    "            (coded_sp - coded_sps_mean) / coded_sps_std)\n",
    "    return coded_sps_normalized, coded_sps_mean, coded_sps_std\n",
    "\n",
    "\n",
    "def wav_padding(wav, sr, frame_period, multiple=4):\n",
    "    assert wav.ndim == 1\n",
    "    num_frames = len(wav)\n",
    "    num_frames_padded = int((np.ceil((np.floor(num_frames / (sr * frame_period / 1000)) +\n",
    "                                      1) / multiple + 1) * multiple - 1) * (sr * frame_period / 1000))\n",
    "    num_frames_diff = num_frames_padded - num_frames\n",
    "    num_pad_left = num_frames_diff // 2\n",
    "    num_pad_right = num_frames_diff - num_pad_left\n",
    "    wav_padded = np.pad(wav, (num_pad_left, num_pad_right),\n",
    "                        'constant', constant_values=0)\n",
    "\n",
    "    return wav_padded\n",
    "\n",
    "\n",
    "def pitch_conversion(f0, mean_log_src, std_log_src, mean_log_target, std_log_target):\n",
    "    # Logarithm Gaussian Normalization for Pitch Conversions\n",
    "    f0_converted = np.exp((np.log(f0) - mean_log_src) /\n",
    "                          std_log_src * std_log_target + mean_log_target)\n",
    "    return f0_converted\n",
    "\n",
    "\n",
    "def world_decode_spectral_envelop(coded_sp, fs):\n",
    "    fftlen = pyworld.get_cheaptrick_fft_size(fs)\n",
    "    decoded_sp = pyworld.decode_spectral_envelope(coded_sp, fs, fftlen)\n",
    "    return decoded_sp\n",
    "\n",
    "\n",
    "def world_speech_synthesis(f0, decoded_sp, ap, fs, frame_period):\n",
    "    wav = pyworld.synthesize(f0, decoded_sp, ap, fs, frame_period)\n",
    "    wav = wav.astype(np.float32)\n",
    "    return wav\n",
    "\n",
    "\n",
    "def sample_train_data(dataset_A, dataset_B, n_frames=128):\n",
    "    # Created Pytorch custom dataset instead\n",
    "    num_samples = min(len(dataset_A), len(dataset_B))\n",
    "    train_data_A_idx = np.arange(len(dataset_A))\n",
    "    train_data_B_idx = np.arange(len(dataset_B))\n",
    "    np.random.shuffle(train_data_A_idx)\n",
    "    np.random.shuffle(train_data_B_idx)\n",
    "    train_data_A_idx_subset = train_data_A_idx[:num_samples]\n",
    "    train_data_B_idx_subset = train_data_B_idx[:num_samples]\n",
    "\n",
    "    train_data_A = list()\n",
    "    train_data_B = list()\n",
    "\n",
    "    for idx_A, idx_B in zip(train_data_A_idx_subset, train_data_B_idx_subset):\n",
    "        data_A = dataset_A[idx_A]\n",
    "        frames_A_total = data_A.shape[1]\n",
    "        assert frames_A_total >= n_frames\n",
    "        start_A = np.random.randint(frames_A_total - n_frames + 1)\n",
    "        end_A = start_A + n_frames\n",
    "        train_data_A.append(data_A[:, start_A:end_A])\n",
    "\n",
    "        data_B = dataset_B[idx_B]\n",
    "        frames_B_total = data_B.shape[1]\n",
    "        assert frames_B_total >= n_frames\n",
    "        start_B = np.random.randint(frames_B_total - n_frames + 1)\n",
    "        end_B = start_B + n_frames\n",
    "        train_data_B.append(data_B[:, start_B:end_B])\n",
    "\n",
    "    train_data_A = np.array(train_data_A)\n",
    "    train_data_B = np.array(train_data_B)\n",
    "\n",
    "    return train_data_A, train_data_B\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    wavs = load_wavs(\"../data/vcc2016_training/SF1/\", 16000)\n",
    "    # pprint(wavs)\n",
    "\n",
    "    f0, timeaxis, sp, ap = world_decompose(wavs[0], 16000, 5.0)\n",
    "    print(f0.shape, timeaxis.shape, sp.shape, ap.shape)\n",
    "\n",
    "    coded_sp = world_encode_spectral_envelop(sp, 16000, 24)\n",
    "    print(coded_sp.shape)\n",
    "\n",
    "    f0s, timeaxes, sps, aps, coded_sps = world_encode_data(wavs, 16000, 5, 24)\n",
    "    # print(f0s)\n",
    "\n",
    "    log_f0_mean, log_f0_std = logf0_statistics(f0s)\n",
    "    # print(log_f0_mean)\n",
    "\n",
    "    coded_sps_transposed = transpose_in_list(lst=coded_sps)\n",
    "    # print(coded_sps_transposed)\n",
    "\n",
    "    coded_sps_norm, coded_sps_mean, coded_sps_std = coded_sps_normalization_fit_transform(\n",
    "        coded_sps=coded_sps_transposed)\n",
    "    print(\n",
    "        \"Total time for preprcessing-> {:.4f}\".format(time.time() - start_time))\n",
    "\n",
    "    print(len(coded_sps_norm), coded_sps_norm[0].shape)\n",
    "    temp_A = np.random.randn(162, 24, 550)\n",
    "    temp_B = np.random.randn(158, 24, 550)\n",
    "\n",
    "    a, b = sample_train_data(temp_A, temp_B)\n",
    "    print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96fde10-b616-4bea-ab43-b92d8384d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Classes\n",
    "import preprocess\n",
    "\n",
    "\n",
    "def save_pickle(variable, fileName):\n",
    "    with open(fileName, 'wb') as f:\n",
    "        pickle.dump(variable, f)\n",
    "\n",
    "\n",
    "def load_pickle_file(fileName):\n",
    "    with open(fileName, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def preprocess_for_training(train_A_dir, train_B_dir, cache_folder):\n",
    "    num_mcep = 36\n",
    "    sampling_rate = 16000\n",
    "    frame_period = 5.0\n",
    "    n_frames = 128\n",
    "\n",
    "    print(\"Starting to prepocess data.......\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    wavs_A = preprocess.load_wavs(wav_dir=train_A_dir, sr=sampling_rate)\n",
    "    wavs_B = preprocess.load_wavs(wav_dir=train_B_dir, sr=sampling_rate)\n",
    "\n",
    "    f0s_A, timeaxes_A, sps_A, aps_A, coded_sps_A = preprocess.world_encode_data(\n",
    "        wave=wavs_A, fs=sampling_rate, frame_period=frame_period, coded_dim=num_mcep)\n",
    "    f0s_B, timeaxes_B, sps_B, aps_B, coded_sps_B = preprocess.world_encode_data(\n",
    "        wave=wavs_B, fs=sampling_rate, frame_period=frame_period, coded_dim=num_mcep)\n",
    "\n",
    "    log_f0s_mean_A, log_f0s_std_A = preprocess.logf0_statistics(f0s=f0s_A)\n",
    "    log_f0s_mean_B, log_f0s_std_B = preprocess.logf0_statistics(f0s=f0s_B)\n",
    "\n",
    "    print(\"Log Pitch A\")\n",
    "    print(\"Mean: {:.4f}, Std: {:.4f}\".format(log_f0s_mean_A, log_f0s_std_A))\n",
    "    print(\"Log Pitch B\")\n",
    "    print(\"Mean: {:.4f}, Std: {:.4f}\".format(log_f0s_mean_B, log_f0s_std_B))\n",
    "\n",
    "    coded_sps_A_transposed = preprocess.transpose_in_list(lst=coded_sps_A)\n",
    "    coded_sps_B_transposed = preprocess.transpose_in_list(lst=coded_sps_B)\n",
    "\n",
    "    coded_sps_A_norm, coded_sps_A_mean, coded_sps_A_std = preprocess.coded_sps_normalization_fit_transform(\n",
    "        coded_sps=coded_sps_A_transposed)\n",
    "    coded_sps_B_norm, coded_sps_B_mean, coded_sps_B_std = preprocess.coded_sps_normalization_fit_transform(\n",
    "        coded_sps=coded_sps_B_transposed)\n",
    "\n",
    "    if not os.path.exists(cache_folder):\n",
    "        os.makedirs(cache_folder)\n",
    "\n",
    "    np.savez(os.path.join(cache_folder, 'logf0s_normalization.npz'),\n",
    "             mean_A=log_f0s_mean_A,\n",
    "             std_A=log_f0s_std_A,\n",
    "             mean_B=log_f0s_mean_B,\n",
    "             std_B=log_f0s_std_B)\n",
    "\n",
    "    np.savez(os.path.join(cache_folder, 'mcep_normalization.npz'),\n",
    "             mean_A=coded_sps_A_mean,\n",
    "             std_A=coded_sps_A_std,\n",
    "             mean_B=coded_sps_B_mean,\n",
    "             std_B=coded_sps_B_std)\n",
    "\n",
    "    save_pickle(variable=coded_sps_A_norm,\n",
    "                fileName=os.path.join(cache_folder, \"coded_sps_A_norm.pickle\"))\n",
    "    save_pickle(variable=coded_sps_B_norm,\n",
    "                fileName=os.path.join(cache_folder, \"coded_sps_B_norm.pickle\"))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Preprocessing finsihed!! see your directory ../cache for cached preprocessed data\")\n",
    "\n",
    "    print(\"Time taken for preprocessing {:.4f} seconds\".format(\n",
    "        end_time - start_time))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Prepare data for training Cycle GAN using PyTorch')\n",
    "    train_A_dir_default = './data/S0913/'\n",
    "    train_B_dir_default = './data/gaoxiaosong/'\n",
    "    cache_folder_default = './cache/'\n",
    "\n",
    "    parser.add_argument('--train_A_dir', type=str,\n",
    "                        help=\"Directory for source voice sample\", default=train_A_dir_default)\n",
    "    parser.add_argument('--train_B_dir', type=str,\n",
    "                        help=\"Directory for target voice sample\", default=train_B_dir_default)\n",
    "    parser.add_argument('--cache_folder', type=str,\n",
    "                        help=\"Store preprocessed data in cache folders\", default=cache_folder_default)\n",
    "    argv = parser.parse_args()\n",
    "\n",
    "    train_A_dir = argv.train_A_dir\n",
    "    train_B_dir = argv.train_B_dir\n",
    "    cache_folder = argv.cache_folder\n",
    "\n",
    "    preprocess_for_training(train_A_dir, train_B_dir, cache_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77561679-abe9-4224-96ca-b314972d5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GLU, self).__init__()\n",
    "        # Custom Implementation because the Voice Conversion Cycle GAN\n",
    "        # paper assumes GLU won't reduce the dimension of tensor by 2.\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input * torch.sigmoid(input)\n",
    "\n",
    "\n",
    "class PixelShuffle(nn.Module):\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(PixelShuffle, self).__init__()\n",
    "        # Custom Implementation because PyTorch PixelShuffle requires,\n",
    "        # 4D input. Whereas, in this case we have have 3D array\n",
    "        self.upscale_factor = upscale_factor\n",
    "\n",
    "    def forward(self, input):\n",
    "        n = input.shape[0]\n",
    "        c_out = input.shape[1] // 2\n",
    "        w_new = input.shape[2] * 2\n",
    "        return input.view(n, c_out, w_new)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "\n",
    "        # self.residualLayer = nn.Sequential(nn.Conv1d(in_channels=in_channels,\n",
    "        #                                              out_channels=out_channels,\n",
    "        #                                              kernel_size=kernel_size,\n",
    "        #                                              stride=1,\n",
    "        #                                              padding=padding),\n",
    "        #                                    nn.InstanceNorm1d(\n",
    "        #                                        num_features=out_channels,\n",
    "        #                                        affine=True),\n",
    "        #                                    GLU(),\n",
    "        #                                    nn.Conv1d(in_channels=out_channels,\n",
    "        #                                              out_channels=in_channels,\n",
    "        #                                              kernel_size=kernel_size,\n",
    "        #                                              stride=1,\n",
    "        #                                              padding=padding),\n",
    "        #                                    nn.InstanceNorm1d(\n",
    "        #                                        num_features=in_channels,\n",
    "        #                                        affine=True)\n",
    "        #                                    )\n",
    "\n",
    "        self.conv1d_layer = nn.Sequential(nn.Conv1d(in_channels=in_channels,\n",
    "                                                    out_channels=out_channels,\n",
    "                                                    kernel_size=kernel_size,\n",
    "                                                    stride=1,\n",
    "                                                    padding=padding),\n",
    "                                          nn.InstanceNorm1d(num_features=out_channels,\n",
    "                                                            affine=True))\n",
    "\n",
    "        self.conv_layer_gates = nn.Sequential(nn.Conv1d(in_channels=in_channels,\n",
    "                                                        out_channels=out_channels,\n",
    "                                                        kernel_size=kernel_size,\n",
    "                                                        stride=1,\n",
    "                                                        padding=padding),\n",
    "                                              nn.InstanceNorm1d(num_features=out_channels,\n",
    "                                                                affine=True))\n",
    "\n",
    "        self.conv1d_out_layer = nn.Sequential(nn.Conv1d(in_channels=out_channels,\n",
    "                                                        out_channels=in_channels,\n",
    "                                                        kernel_size=kernel_size,\n",
    "                                                        stride=1,\n",
    "                                                        padding=padding),\n",
    "                                              nn.InstanceNorm1d(num_features=in_channels,\n",
    "                                                                affine=True))\n",
    "\n",
    "    def forward(self, input):\n",
    "        h1_norm = self.conv1d_layer(input)\n",
    "        h1_gates_norm = self.conv_layer_gates(input)\n",
    "\n",
    "        # GLU\n",
    "        h1_glu = h1_norm * torch.sigmoid(h1_gates_norm)\n",
    "\n",
    "        h2_norm = self.conv1d_out_layer(h1_glu)\n",
    "        return input + h2_norm\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "class downSample_Generator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(downSample_Generator, self).__init__()\n",
    "\n",
    "        self.convLayer = nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
    "                                                 out_channels=out_channels,\n",
    "                                                 kernel_size=kernel_size,\n",
    "                                                 stride=stride,\n",
    "                                                 padding=padding),\n",
    "                                       nn.InstanceNorm2d(num_features=out_channels,\n",
    "                                                         affine=True))\n",
    "        self.convLayer_gates = nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
    "                                                       out_channels=out_channels,\n",
    "                                                       kernel_size=kernel_size,\n",
    "                                                       stride=stride,\n",
    "                                                       padding=padding),\n",
    "                                             nn.InstanceNorm2d(num_features=out_channels,\n",
    "                                                               affine=True))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # GLU\n",
    "        return self.convLayer(input) * torch.sigmoid(self.convLayer_gates(input))\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # 2D Conv Layer \n",
    "        self.conv1 = nn.Conv2d(in_channels=1,  # TODO 1 ?\n",
    "                               out_channels=128,\n",
    "                               kernel_size=(5, 15),\n",
    "                               stride=(1, 1),\n",
    "                               padding=(2, 7))\n",
    "\n",
    "        self.conv1_gates = nn.Conv2d(in_channels=1,  # TODO 1 ?\n",
    "                                     out_channels=128,\n",
    "                                     kernel_size=(5, 15),\n",
    "                                     stride=1,\n",
    "                                     padding=(2, 7))\n",
    "\n",
    "        # 2D Downsample Layer\n",
    "        self.downSample1 = downSample_Generator(in_channels=128,\n",
    "                                                out_channels=256,\n",
    "                                                kernel_size=5,\n",
    "                                                stride=2,\n",
    "                                                padding=2)\n",
    "\n",
    "        self.downSample2 = downSample_Generator(in_channels=256,\n",
    "                                                out_channels=256,\n",
    "                                                kernel_size=5,\n",
    "                                                stride=2,\n",
    "                                                padding=2)\n",
    "\n",
    "        # 2D -> 1D Conv\n",
    "        self.conv2dto1dLayer = nn.Sequential(nn.Conv1d(in_channels=2304,\n",
    "                                                       out_channels=256,\n",
    "                                                       kernel_size=1,\n",
    "                                                       stride=1,\n",
    "                                                       padding=0),\n",
    "                                             nn.InstanceNorm1d(num_features=256,\n",
    "                                                               affine=True))\n",
    "\n",
    "        # Residual Blocks\n",
    "        self.residualLayer1 = ResidualLayer(in_channels=256,\n",
    "                                            out_channels=512,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "        self.residualLayer2 = ResidualLayer(in_channels=256,\n",
    "                                            out_channels=512,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "        self.residualLayer3 = ResidualLayer(in_channels=256,\n",
    "                                            out_channels=512,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "        self.residualLayer4 = ResidualLayer(in_channels=256,\n",
    "                                            out_channels=512,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "        self.residualLayer5 = ResidualLayer(in_channels=256,\n",
    "                                            out_channels=512,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "        self.residualLayer6 = ResidualLayer(in_channels=256,\n",
    "                                            out_channels=512,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "\n",
    "        # 1D -> 2D Conv\n",
    "        self.conv1dto2dLayer = nn.Sequential(nn.Conv1d(in_channels=256,\n",
    "                                                       out_channels=2304,\n",
    "                                                       kernel_size=1,\n",
    "                                                       stride=1,\n",
    "                                                       padding=0),\n",
    "                                             nn.InstanceNorm1d(num_features=2304,\n",
    "                                                               affine=True))\n",
    "\n",
    "        # UpSample Layer\n",
    "        self.upSample1 = self.upSample(in_channels=256,\n",
    "                                       out_channels=1024,\n",
    "                                       kernel_size=5,\n",
    "                                       stride=1,\n",
    "                                       padding=2)\n",
    "\n",
    "        self.upSample2 = self.upSample(in_channels=256,\n",
    "                                       out_channels=512,\n",
    "                                       kernel_size=5,\n",
    "                                       stride=1,\n",
    "                                       padding=2)\n",
    "\n",
    "        self.lastConvLayer = nn.Conv2d(in_channels=128,\n",
    "                                       out_channels=1,\n",
    "                                       kernel_size=(5, 15),\n",
    "                                       stride=(1, 1),\n",
    "                                       padding=(2, 7))\n",
    "\n",
    "    def downSample(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        self.ConvLayer = nn.Sequential(nn.Conv1d(in_channels=in_channels,\n",
    "                                                 out_channels=out_channels,\n",
    "                                                 kernel_size=kernel_size,\n",
    "                                                 stride=stride,\n",
    "                                                 padding=padding),\n",
    "                                       nn.InstanceNorm1d(\n",
    "                                           num_features=out_channels,\n",
    "                                           affine=True),\n",
    "                                       GLU())\n",
    "\n",
    "        return self.ConvLayer\n",
    "\n",
    "    def upSample(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        self.convLayer = nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
    "                                                 out_channels=out_channels,\n",
    "                                                 kernel_size=kernel_size,\n",
    "                                                 stride=stride,\n",
    "                                                 padding=padding),\n",
    "                                       nn.PixelShuffle(upscale_factor=2),\n",
    "                                       nn.InstanceNorm2d(\n",
    "                                           num_features=out_channels // 4,\n",
    "                                           affine=True),\n",
    "                                       GLU())\n",
    "        return self.convLayer\n",
    "\n",
    "    def forward(self, input):\n",
    "        # GLU\n",
    "        # print(\"Generator forward input: \", input.shape)\n",
    "        input = input.unsqueeze(1)\n",
    "        # print(\"Generator forward input: \", input.shape)\n",
    "        conv1 = self.conv1(input) * torch.sigmoid(self.conv1_gates(input))\n",
    "        # print(\"Generator forward conv1: \", conv1.shape)\n",
    "\n",
    "        # DownloadSample\n",
    "        downsample1 = self.downSample1(conv1)\n",
    "        # print(\"Generator forward downsample1: \", downsample1.shape)\n",
    "        downsample2 = self.downSample2(downsample1)\n",
    "        # print(\"Generator forward downsample2: \", downsample2.shape)\n",
    "\n",
    "        # 2D -> 1D\n",
    "        # reshape\n",
    "        reshape2dto1d = downsample2.view(downsample2.size(0), 2304, 1, -1)\n",
    "        reshape2dto1d = reshape2dto1d.squeeze(2)\n",
    "        # print(\"Generator forward reshape2dto1d: \", reshape2dto1d.shape)\n",
    "        conv2dto1d_layer = self.conv2dto1dLayer(reshape2dto1d)\n",
    "        # print(\"Generator forward conv2dto1d_layer: \", conv2dto1d_layer.shape)\n",
    "\n",
    "        residual_layer_1 = self.residualLayer1(conv2dto1d_layer)\n",
    "        residual_layer_2 = self.residualLayer2(residual_layer_1)\n",
    "        residual_layer_3 = self.residualLayer3(residual_layer_2)\n",
    "        residual_layer_4 = self.residualLayer4(residual_layer_3)\n",
    "        residual_layer_5 = self.residualLayer5(residual_layer_4)\n",
    "        residual_layer_6 = self.residualLayer6(residual_layer_5)\n",
    "\n",
    "        # print(\"Generator forward residual_layer_6: \", residual_layer_6.shape)\n",
    "\n",
    "        # 1D -> 2D\n",
    "        conv1dto2d_layer = self.conv1dto2dLayer(residual_layer_6)\n",
    "        # print(\"Generator forward conv1dto2d_layer: \", conv1dto2d_layer.shape)\n",
    "        # reshape\n",
    "        reshape1dto2d = conv1dto2d_layer.unsqueeze(2)\n",
    "        reshape1dto2d = reshape1dto2d.view(reshape1dto2d.size(0), 256, 9, -1)\n",
    "        # print(\"Generator forward reshape1dto2d: \", reshape1dto2d.shape)\n",
    "\n",
    "        # UpSample\n",
    "        upsample_layer_1 = self.upSample1(reshape1dto2d)\n",
    "        # print(\"Generator forward upsample_layer_1: \", upsample_layer_1.shape)\n",
    "        upsample_layer_2 = self.upSample2(upsample_layer_1)\n",
    "        # print(\"Generator forward upsample_layer_2: \", upsample_layer_2.shape)\n",
    "\n",
    "        output = self.lastConvLayer(upsample_layer_2)\n",
    "        # print(\"Generator forward output: \", output.shape)\n",
    "        output = output.squeeze(1)\n",
    "        # print(\"Generator forward output: \", output.shape)\n",
    "        return output\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.convLayer1 = nn.Sequential(nn.Conv2d(in_channels=1,\n",
    "                                                  out_channels=128,\n",
    "                                                  kernel_size=(3, 3),\n",
    "                                                  stride=(1, 1),\n",
    "                                                  padding=(1, 1)),\n",
    "                                        GLU())\n",
    "\n",
    "        # DownSample Layer\n",
    "        self.downSample1 = self.downSample(in_channels=128,\n",
    "                                           out_channels=256,\n",
    "                                           kernel_size=(3, 3),\n",
    "                                           stride=(2, 2),\n",
    "                                           padding=1)\n",
    "\n",
    "        self.downSample2 = self.downSample(in_channels=256,\n",
    "                                           out_channels=512,\n",
    "                                           kernel_size=(3, 3),\n",
    "                                           stride=[2, 2],\n",
    "                                           padding=1)\n",
    "\n",
    "        self.downSample3 = self.downSample(in_channels=512,\n",
    "                                           out_channels=1024,\n",
    "                                           kernel_size=[3, 3],\n",
    "                                           stride=[2, 2],\n",
    "                                           padding=1)\n",
    "\n",
    "        self.downSample4 = self.downSample(in_channels=1024,\n",
    "                                           out_channels=1024,\n",
    "                                           kernel_size=[1, 5],\n",
    "                                           stride=(1, 1),\n",
    "                                           padding=(0, 2))\n",
    "\n",
    "        # Conv Layer\n",
    "        self.outputConvLayer = nn.Sequential(nn.Conv2d(in_channels=1024,\n",
    "                                                       out_channels=1,\n",
    "                                                       kernel_size=(1, 3),\n",
    "                                                       stride=[1, 1],\n",
    "                                                       padding=[0, 1]))\n",
    "\n",
    "    def downSample(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        convLayer = nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
    "                                            out_channels=out_channels,\n",
    "                                            kernel_size=kernel_size,\n",
    "                                            stride=stride,\n",
    "                                            padding=padding),\n",
    "                                  nn.InstanceNorm2d(num_features=out_channels,\n",
    "                                                    affine=True),\n",
    "                                  GLU())\n",
    "        return convLayer\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input has shape [batch_size, num_features, time]\n",
    "        # discriminator requires shape [batchSize, 1, num_features, time]\n",
    "        input = input.unsqueeze(1)\n",
    "        # print(\"Discriminator forward input: \", input.shape)\n",
    "        conv_layer_1 = self.convLayer1(input)\n",
    "        # print(\"Discriminator forward conv_layer_1: \", conv_layer_1.shape)\n",
    "\n",
    "        downsample1 = self.downSample1(conv_layer_1)\n",
    "        # print(\"Discriminator forward downsample1: \", downsample1.shape)\n",
    "        downsample2 = self.downSample2(downsample1)\n",
    "        # print(\"Discriminator forward downsample2: \", downsample2.shape)\n",
    "        downsample3 = self.downSample3(downsample2)\n",
    "        # print(\"Discriminator forward downsample3: \", downsample3.shape)\n",
    "\n",
    "        # downsample3 = downsample3.contiguous().permute(0, 2, 3, 1).contiguous()\n",
    "        # print(\"Discriminator forward downsample3: \", downsample3.shape)\n",
    "\n",
    "        output = torch.sigmoid(self.outputConvLayer(downsample3))\n",
    "        # print(\"Discriminator forward output: \", output.shape)\n",
    "        return output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "\n",
    "    args = sys.argv\n",
    "    print(args)\n",
    "    if len(args) > 1:\n",
    "        if args[1] == \"g\":\n",
    "            generator = Generator()\n",
    "            print(generator)\n",
    "        elif args[1] == \"d\":\n",
    "            discriminator = Discriminator()\n",
    "            print(discriminator)\n",
    "\n",
    "        sys.exit(0)\n",
    "\n",
    "    # Generator Dimensionality Testing\n",
    "    input = torch.randn(10, 36, 1100)  # (N, C_in, Width) For Conv1d\n",
    "    np.random.seed(0)\n",
    "    # print(np.random.randn(10))\n",
    "    input = np.random.randn(2, 36, 128)\n",
    "    input = torch.from_numpy(input).float()\n",
    "    print(\"Generator input: \", input.shape)\n",
    "    generator = Generator()\n",
    "    output = generator(input)\n",
    "    print(\"Generator output shape: \", output.shape)\n",
    "\n",
    "    # Discriminator Dimensionality Testing\n",
    "    # input = torch.randn(32, 1, 24, 128)  # (N, C_in, height, width) For Conv2d\n",
    "    discriminator = Discriminator()\n",
    "    output = discriminator(output)\n",
    "    print(\"Discriminator output shape \", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f5d2f4d-1385-4332-bf60-e6980a48c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "\n",
    "class CycleGANTraining(object):\n",
    "    def __init__(self,\n",
    "                 logf0s_normalization,\n",
    "                 mcep_normalization,\n",
    "                 coded_sps_A_norm,\n",
    "                 coded_sps_B_norm,\n",
    "                 model_checkpoint,\n",
    "                 validation_A_dir,\n",
    "                 output_A_dir,\n",
    "                 validation_B_dir,\n",
    "                 output_B_dir,\n",
    "                 restart_training_at=None):\n",
    "        self.start_epoch = 0\n",
    "        self.num_epochs = 200000  # 5000\n",
    "        self.mini_batch_size = 1  # 1\n",
    "        self.dataset_A = self.loadPickleFile(coded_sps_A_norm)\n",
    "        self.dataset_B = self.loadPickleFile(coded_sps_B_norm)\n",
    "        self.device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Speech Parameters\n",
    "        logf0s_normalization = np.load(logf0s_normalization)\n",
    "        self.log_f0s_mean_A = logf0s_normalization['mean_A']\n",
    "        self.log_f0s_std_A = logf0s_normalization['std_A']\n",
    "        self.log_f0s_mean_B = logf0s_normalization['mean_B']\n",
    "        self.log_f0s_std_B = logf0s_normalization['std_B']\n",
    "\n",
    "        mcep_normalization = np.load(mcep_normalization)\n",
    "        self.coded_sps_A_mean = mcep_normalization['mean_A']\n",
    "        self.coded_sps_A_std = mcep_normalization['std_A']\n",
    "        self.coded_sps_B_mean = mcep_normalization['mean_B']\n",
    "        self.coded_sps_B_std = mcep_normalization['std_B']\n",
    "\n",
    "        # Generator and Discriminator\n",
    "        self.generator_A2B = Generator().to(self.device)\n",
    "        self.generator_B2A = Generator().to(self.device)\n",
    "        self.discriminator_A = Discriminator().to(self.device)\n",
    "        self.discriminator_B = Discriminator().to(self.device)\n",
    "\n",
    "        # Loss Functions\n",
    "        criterion_mse = torch.nn.MSELoss()\n",
    "\n",
    "        # Optimizer\n",
    "        g_params = list(self.generator_A2B.parameters()) + \\\n",
    "                   list(self.generator_B2A.parameters())\n",
    "        d_params = list(self.discriminator_A.parameters()) + \\\n",
    "                   list(self.discriminator_B.parameters())\n",
    "\n",
    "        # Initial learning rates\n",
    "        self.generator_lr = 2e-4  # 0.0002\n",
    "        self.discriminator_lr = 1e-4  # 0.0001\n",
    "\n",
    "        # Learning rate decay\n",
    "        self.generator_lr_decay = self.generator_lr / 200000\n",
    "        self.discriminator_lr_decay = self.discriminator_lr / 200000\n",
    "\n",
    "        # Starts learning rate decay from after this many iterations have passed\n",
    "        self.start_decay = 10000  # 200000\n",
    "\n",
    "        self.generator_optimizer = torch.optim.Adam(\n",
    "            g_params, lr=self.generator_lr, betas=(0.5, 0.999))\n",
    "        self.discriminator_optimizer = torch.optim.Adam(\n",
    "            d_params, lr=self.discriminator_lr, betas=(0.5, 0.999))\n",
    "\n",
    "        # To Load save previously saved models\n",
    "        self.modelCheckpoint = model_checkpoint\n",
    "        os.makedirs(self.modelCheckpoint, exist_ok=True)\n",
    "\n",
    "        # Validation set Parameters\n",
    "        self.validation_A_dir = validation_A_dir\n",
    "        self.output_A_dir = output_A_dir\n",
    "        os.makedirs(self.output_A_dir, exist_ok=True)\n",
    "        self.validation_B_dir = validation_B_dir\n",
    "        self.output_B_dir = output_B_dir\n",
    "        os.makedirs(self.output_B_dir, exist_ok=True)\n",
    "\n",
    "        # Storing Discriminatior and Generator Loss\n",
    "        self.generator_loss_store = []\n",
    "        self.discriminator_loss_store = []\n",
    "\n",
    "        self.file_name = 'log_store_non_sigmoid.txt'\n",
    "\n",
    "        if restart_training_at is not None:\n",
    "            # Training will resume from previous checkpoint\n",
    "            self.start_epoch = self.loadModel(restart_training_at)\n",
    "            print(\"Training resumed\")\n",
    "\n",
    "    def adjust_lr_rate(self, optimizer, name='generator'):\n",
    "        if name == 'generator':\n",
    "            self.generator_lr = max(\n",
    "                0., self.generator_lr - self.generator_lr_decay)\n",
    "            for param_groups in optimizer.param_groups:\n",
    "                param_groups['lr'] = self.generator_lr\n",
    "        else:\n",
    "            self.discriminator_lr = max(\n",
    "                0., self.discriminator_lr - self.discriminator_lr_decay)\n",
    "            for param_groups in optimizer.param_groups:\n",
    "                param_groups['lr'] = self.discriminator_lr\n",
    "\n",
    "    def reset_grad(self):\n",
    "        self.generator_optimizer.zero_grad()\n",
    "        self.discriminator_optimizer.zero_grad()\n",
    "\n",
    "    def train(self):\n",
    "        # Training Begins\n",
    "        for epoch in range(self.start_epoch, self.num_epochs):\n",
    "            start_time_epoch = time.time()\n",
    "\n",
    "            # Constants\n",
    "            cycle_loss_lambda = 10\n",
    "            identity_loss_lambda = 5\n",
    "\n",
    "            # Preparing Dataset\n",
    "            n_samples = len(self.dataset_A)\n",
    "\n",
    "            dataset = trainingDataset(datasetA=self.dataset_A,\n",
    "                                      datasetB=self.dataset_B,\n",
    "                                      n_frames=128)\n",
    "            train_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                                       batch_size=self.mini_batch_size,\n",
    "                                                       shuffle=True,\n",
    "                                                       drop_last=False)\n",
    "\n",
    "            pbar = tqdm(enumerate(train_loader))\n",
    "            for i, (real_A, real_B) in enumerate(train_loader):\n",
    "                num_iterations = (n_samples // self.mini_batch_size) * epoch + i\n",
    "                # print(\"iteration no: \", num_iterations, epoch)\n",
    "\n",
    "                if num_iterations > 10000:\n",
    "                    identity_loss_lambda = 0\n",
    "                if num_iterations > self.start_decay:\n",
    "                    self.adjust_lr_rate(\n",
    "                        self.generator_optimizer, name='generator')\n",
    "                    self.adjust_lr_rate(\n",
    "                        self.generator_optimizer, name='discriminator')\n",
    "\n",
    "                real_A = real_A.to(self.device).float()\n",
    "                real_B = real_B.to(self.device).float()\n",
    "\n",
    "                # Generator Loss function\n",
    "\n",
    "                fake_B = self.generator_A2B(real_A)\n",
    "                cycle_A = self.generator_B2A(fake_B)\n",
    "\n",
    "                fake_A = self.generator_B2A(real_B)\n",
    "                cycle_B = self.generator_A2B(fake_A)\n",
    "\n",
    "                identity_A = self.generator_B2A(real_A)\n",
    "                identity_B = self.generator_A2B(real_B)\n",
    "\n",
    "                d_fake_A = self.discriminator_A(fake_A)\n",
    "                d_fake_B = self.discriminator_B(fake_B)\n",
    "\n",
    "                # for the second step adverserial loss\n",
    "                d_fake_cycle_A = self.discriminator_A(cycle_A)\n",
    "                d_fake_cycle_B = self.discriminator_B(cycle_B)\n",
    "\n",
    "                # Generator Cycle loss\n",
    "                cycleLoss = torch.mean(\n",
    "                    torch.abs(real_A - cycle_A)) + torch.mean(torch.abs(real_B - cycle_B))\n",
    "\n",
    "                # Generator Identity Loss\n",
    "                identiyLoss = torch.mean(\n",
    "                    torch.abs(real_A - identity_A)) + torch.mean(torch.abs(real_B - identity_B))\n",
    "\n",
    "                # Generator Loss\n",
    "                generator_loss_A2B = torch.mean((1 - d_fake_B) ** 2)\n",
    "                generator_loss_B2A = torch.mean((1 - d_fake_A) ** 2)\n",
    "\n",
    "                # Total Generator Loss\n",
    "                generator_loss = generator_loss_A2B + generator_loss_B2A + \\\n",
    "                                 cycle_loss_lambda * cycleLoss + identity_loss_lambda * identiyLoss\n",
    "                self.generator_loss_store.append(generator_loss.item())\n",
    "\n",
    "                # Backprop for Generator\n",
    "                self.reset_grad()\n",
    "                generator_loss.backward()\n",
    "\n",
    "                # if num_iterations > self.start_decay:  # Linearly decay learning rate\n",
    "                #     self.adjust_lr_rate(\n",
    "                #         self.generator_optimizer, name='generator')\n",
    "\n",
    "                self.generator_optimizer.step()\n",
    "\n",
    "                # Discriminator Loss Function\n",
    "\n",
    "                # Discriminator Feed Forward\n",
    "                d_real_A = self.discriminator_A(real_A)\n",
    "                d_real_B = self.discriminator_B(real_B)\n",
    "\n",
    "                generated_A = self.generator_B2A(real_B)\n",
    "                d_fake_A = self.discriminator_A(generated_A)\n",
    "\n",
    "                # for the second step adverserial loss\n",
    "                cycled_B = self.generator_A2B(generated_A)\n",
    "                d_cycled_B = self.discriminator_B(cycled_B)\n",
    "\n",
    "                generated_B = self.generator_A2B(real_A)\n",
    "                d_fake_B = self.discriminator_B(generated_B)\n",
    "\n",
    "                # for the second step adverserial loss\n",
    "                cycled_A = self.generator_B2A(generated_B)\n",
    "                d_cycled_A = self.discriminator_A(cycled_A)\n",
    "\n",
    "                # Loss Functions\n",
    "                d_loss_A_real = torch.mean((1 - d_real_A) ** 2)\n",
    "                d_loss_A_fake = torch.mean((0 - d_fake_A) ** 2)\n",
    "                d_loss_A = (d_loss_A_real + d_loss_A_fake) / 2.0\n",
    "\n",
    "                d_loss_B_real = torch.mean((1 - d_real_B) ** 2)\n",
    "                d_loss_B_fake = torch.mean((0 - d_fake_B) ** 2)\n",
    "                d_loss_B = (d_loss_B_real + d_loss_B_fake) / 2.0\n",
    "\n",
    "                # the second step adverserial loss\n",
    "                d_loss_A_cycled = torch.mean((0 - d_cycled_A) ** 2)\n",
    "                d_loss_B_cycled = torch.mean((0 - d_cycled_B) ** 2)\n",
    "                d_loss_A_2nd = (d_loss_A_real + d_loss_A_cycled) / 2.0\n",
    "                d_loss_B_2nd = (d_loss_B_real + d_loss_B_cycled) / 2.0\n",
    "\n",
    "                # Final Loss for discriminator with the second step adverserial loss\n",
    "                d_loss = (d_loss_A + d_loss_B) / 2.0 + (d_loss_A_2nd + d_loss_B_2nd) / 2.0\n",
    "                self.discriminator_loss_store.append(d_loss.item())\n",
    "\n",
    "                # Backprop for Discriminator\n",
    "                self.reset_grad()\n",
    "                d_loss.backward()\n",
    "\n",
    "                # if num_iterations > self.start_decay:  # Linearly decay learning rate\n",
    "                #     self.adjust_lr_rate(\n",
    "                #         self.discriminator_optimizer, name='discriminator')\n",
    "\n",
    "                self.discriminator_optimizer.step()\n",
    "\n",
    "                if (i + 1) % 2 == 0:\n",
    "                    pbar.set_description(\n",
    "                        \"Iter:{} Generator Loss:{:.4f} Discrimator Loss:{:.4f} GA2B:{:.4f} GB2A:{:.4f} G_id:{:.4f} G_cyc:{:.4f} D_A:{:.4f} D_B:{:.4f}\".format(\n",
    "                            num_iterations,\n",
    "                            generator_loss.item(),\n",
    "                            # loss['generator_loss'],\n",
    "                            d_loss.item(), generator_loss_A2B, generator_loss_B2A, identiyLoss, cycleLoss, d_loss_A,\n",
    "                            d_loss_B))\n",
    "\n",
    "            #                 if num_iterations % 50 == 0:\n",
    "            #                     store_to_file = \"Iter:{}\\t Generator Loss:{:.4f} Discrimator Loss:{:.4f} \\tGA2B:{:.4f} GB2A:{:.4f} G_id:{:.4f} G_cyc:{:.4f} D_A:{:.4f} D_B:{:.4f}\".format(\n",
    "            #                         num_iterations, generator_loss.item(), d_loss.item(), generator_loss_A2B, generator_loss_B2A,\n",
    "            #                         identiyLoss, cycleLoss, d_loss_A, d_loss_B)\n",
    "            #                     print(\n",
    "            #                         \"Iter:{}\\t Generator Loss:{:.4f} Discrimator Loss:{:.4f} \\tGA2B:{:.4f} GB2A:{:.4f} G_id:{:.4f} G_cyc:{:.4f} D_A:{:.4f} D_B:{:.4f}\".format(\n",
    "            #                             num_iterations, generator_loss.item(), d_loss.item(), generator_loss_A2B,\n",
    "            #                             generator_loss_B2A, identiyLoss, cycleLoss, d_loss_A, d_loss_B))\n",
    "            #                     self.store_to_file(store_to_file)\n",
    "\n",
    "            #             end_time = time.time()\n",
    "            #             store_to_file = \"Epoch: {} Generator Loss: {:.4f} Discriminator Loss: {}, Time: {:.2f}\\n\\n\".format(\n",
    "            #                 epoch, generator_loss.item(), d_loss.item(), end_time - start_time_epoch)\n",
    "            #             self.store_to_file(store_to_file)\n",
    "            #             print(\"Epoch: {} Generator Loss: {:.4f} Discriminator Loss: {}, Time: {:.2f}\\n\\n\".format(\n",
    "            #                 epoch, generator_loss.item(), d_loss.item(), end_time - start_time_epoch))\n",
    "\n",
    "            if epoch % 2000 == 0 and epoch != 0:\n",
    "                end_time = time.time()\n",
    "                store_to_file = \"Epoch: {} Generator Loss: {:.4f} Discriminator Loss: {}, Time: {:.2f}\\n\\n\".format(\n",
    "                    epoch, generator_loss.item(), d_loss.item(), end_time - start_time_epoch)\n",
    "                self.store_to_file(store_to_file)\n",
    "                print(\"Epoch: {} Generator Loss: {:.4f} Discriminator Loss: {}, Time: {:.2f}\\n\\n\".format(\n",
    "                    epoch, generator_loss.item(), d_loss.item(), end_time - start_time_epoch))\n",
    "\n",
    "                # Save the Entire model\n",
    "                print(\"Saving model Checkpoint  ......\")\n",
    "                store_to_file = \"Saving model Checkpoint  ......\"\n",
    "                self.store_to_file(store_to_file)\n",
    "                self.saveModelCheckPoint(epoch, '{}'.format(\n",
    "                    self.modelCheckpoint + '_CycleGAN_CheckPoint'))\n",
    "                print(\"Model Saved!\")\n",
    "\n",
    "            if epoch % 2000 == 0 and epoch != 0:\n",
    "                # Validation Set\n",
    "                validation_start_time = time.time()\n",
    "                self.validation_for_A_dir()\n",
    "                self.validation_for_B_dir()\n",
    "                validation_end_time = time.time()\n",
    "                store_to_file = \"Time taken for validation Set: {}\".format(\n",
    "                    validation_end_time - validation_start_time)\n",
    "                self.store_to_file(store_to_file)\n",
    "                print(\"Time taken for validation Set: {}\".format(\n",
    "                    validation_end_time - validation_start_time))\n",
    "\n",
    "    def validation_for_A_dir(self):\n",
    "        num_mcep = 36\n",
    "        sampling_rate = 16000\n",
    "        frame_period = 5.0\n",
    "        n_frames = 128\n",
    "        validation_A_dir = self.validation_A_dir\n",
    "        output_A_dir = self.output_A_dir\n",
    "\n",
    "        print(\"Generating Validation Data B from A...\")\n",
    "        for file in os.listdir(validation_A_dir):\n",
    "            filePath = os.path.join(validation_A_dir, file)\n",
    "            wav, _ = librosa.load(filePath, sr=sampling_rate, mono=True)\n",
    "            wav = preprocess.wav_padding(wav=wav,\n",
    "                                         sr=sampling_rate,\n",
    "                                         frame_period=frame_period,\n",
    "                                         multiple=4)\n",
    "            f0, timeaxis, sp, ap = preprocess.world_decompose(\n",
    "                wav=wav, fs=sampling_rate, frame_period=frame_period)\n",
    "            f0_converted = preprocess.pitch_conversion(f0=f0,\n",
    "                                                       mean_log_src=self.log_f0s_mean_A,\n",
    "                                                       std_log_src=self.log_f0s_std_A,\n",
    "                                                       mean_log_target=self.log_f0s_mean_B,\n",
    "                                                       std_log_target=self.log_f0s_std_B)\n",
    "            coded_sp = preprocess.world_encode_spectral_envelop(\n",
    "                sp=sp, fs=sampling_rate, dim=num_mcep)\n",
    "            coded_sp_transposed = coded_sp.T\n",
    "            coded_sp_norm = (coded_sp_transposed -\n",
    "                             self.coded_sps_A_mean) / self.coded_sps_A_std\n",
    "            coded_sp_norm = np.array([coded_sp_norm])\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                coded_sp_norm = torch.from_numpy(coded_sp_norm).cuda().float()\n",
    "            else:\n",
    "                coded_sp_norm = torch.from_numpy(coded_sp_norm).float()\n",
    "\n",
    "            coded_sp_converted_norm = self.generator_A2B(coded_sp_norm)\n",
    "            coded_sp_converted_norm = coded_sp_converted_norm.cpu().detach().numpy()\n",
    "            coded_sp_converted_norm = np.squeeze(coded_sp_converted_norm)\n",
    "            coded_sp_converted = coded_sp_converted_norm * \\\n",
    "                                 self.coded_sps_B_std + self.coded_sps_B_mean\n",
    "            coded_sp_converted = coded_sp_converted.T\n",
    "            coded_sp_converted = np.ascontiguousarray(coded_sp_converted)\n",
    "            decoded_sp_converted = preprocess.world_decode_spectral_envelop(\n",
    "                coded_sp=coded_sp_converted, fs=sampling_rate)\n",
    "            wav_transformed = preprocess.world_speech_synthesis(f0=f0_converted,\n",
    "                                                                decoded_sp=decoded_sp_converted,\n",
    "                                                                ap=ap,\n",
    "                                                                fs=sampling_rate,\n",
    "                                                                frame_period=frame_period)\n",
    "            librosa.output.write_wav(path=os.path.join(output_A_dir, os.path.basename(file)),\n",
    "                                     y=wav_transformed,\n",
    "                                     sr=sampling_rate)\n",
    "\n",
    "    def validation_for_B_dir(self):\n",
    "        num_mcep = 36\n",
    "        sampling_rate = 16000\n",
    "        frame_period = 5.0\n",
    "        n_frames = 128\n",
    "        validation_B_dir = self.validation_B_dir\n",
    "        output_B_dir = self.output_B_dir\n",
    "\n",
    "        print(\"Generating Validation Data A from B...\")\n",
    "        for file in os.listdir(validation_B_dir):\n",
    "            filePath = os.path.join(validation_B_dir, file)\n",
    "            wav, _ = librosa.load(filePath, sr=sampling_rate, mono=True)\n",
    "            wav = preprocess.wav_padding(wav=wav,\n",
    "                                         sr=sampling_rate,\n",
    "                                         frame_period=frame_period,\n",
    "                                         multiple=4)\n",
    "            f0, timeaxis, sp, ap = preprocess.world_decompose(\n",
    "                wav=wav, fs=sampling_rate, frame_period=frame_period)\n",
    "            f0_converted = preprocess.pitch_conversion(f0=f0,\n",
    "                                                       mean_log_src=self.log_f0s_mean_B,\n",
    "                                                       std_log_src=self.log_f0s_std_B,\n",
    "                                                       mean_log_target=self.log_f0s_mean_A,\n",
    "                                                       std_log_target=self.log_f0s_std_A)\n",
    "            coded_sp = preprocess.world_encode_spectral_envelop(\n",
    "                sp=sp, fs=sampling_rate, dim=num_mcep)\n",
    "            coded_sp_transposed = coded_sp.T\n",
    "            coded_sp_norm = (coded_sp_transposed -\n",
    "                             self.coded_sps_B_mean) / self.coded_sps_B_std\n",
    "            coded_sp_norm = np.array([coded_sp_norm])\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                coded_sp_norm = torch.from_numpy(coded_sp_norm).cuda().float()\n",
    "            else:\n",
    "                coded_sp_norm = torch.from_numpy(coded_sp_norm).float()\n",
    "\n",
    "            coded_sp_converted_norm = self.generator_B2A(coded_sp_norm)\n",
    "            coded_sp_converted_norm = coded_sp_converted_norm.cpu().detach().numpy()\n",
    "            coded_sp_converted_norm = np.squeeze(coded_sp_converted_norm)\n",
    "            coded_sp_converted = coded_sp_converted_norm * \\\n",
    "                                 self.coded_sps_A_std + self.coded_sps_A_mean\n",
    "            coded_sp_converted = coded_sp_converted.T\n",
    "            coded_sp_converted = np.ascontiguousarray(coded_sp_converted)\n",
    "            decoded_sp_converted = preprocess.world_decode_spectral_envelop(\n",
    "                coded_sp=coded_sp_converted, fs=sampling_rate)\n",
    "            wav_transformed = preprocess.world_speech_synthesis(f0=f0_converted,\n",
    "                                                                decoded_sp=decoded_sp_converted,\n",
    "                                                                ap=ap,\n",
    "                                                                fs=sampling_rate,\n",
    "                                                                frame_period=frame_period)\n",
    "            librosa.output.write_wav(path=os.path.join(output_B_dir, os.path.basename(file)),\n",
    "                                     y=wav_transformed,\n",
    "                                     sr=sampling_rate)\n",
    "\n",
    "    def savePickle(self, variable, fileName):\n",
    "        with open(fileName, 'wb') as f:\n",
    "            pickle.dump(variable, f)\n",
    "\n",
    "    def loadPickleFile(self, fileName):\n",
    "        with open(fileName, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def store_to_file(self, doc):\n",
    "        doc = doc + \"\\n\"\n",
    "        with open(self.file_name, \"a\") as myfile:\n",
    "            myfile.write(doc)\n",
    "\n",
    "    def saveModelCheckPoint(self, epoch, PATH):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'generator_loss_store': self.generator_loss_store,\n",
    "            'discriminator_loss_store': self.discriminator_loss_store,\n",
    "            'model_genA2B_state_dict': self.generator_A2B.state_dict(),\n",
    "            'model_genB2A_state_dict': self.generator_B2A.state_dict(),\n",
    "            'model_discriminatorA': self.discriminator_A.state_dict(),\n",
    "            'model_discriminatorB': self.discriminator_B.state_dict(),\n",
    "            'generator_optimizer': self.generator_optimizer.state_dict(),\n",
    "            'discriminator_optimizer': self.discriminator_optimizer.state_dict()\n",
    "        }, PATH)\n",
    "\n",
    "    def loadModel(self, PATH):\n",
    "        checkPoint = torch.load(PATH)\n",
    "        self.generator_A2B.load_state_dict(\n",
    "            state_dict=checkPoint['model_genA2B_state_dict'])\n",
    "        self.generator_B2A.load_state_dict(\n",
    "            state_dict=checkPoint['model_genB2A_state_dict'])\n",
    "        self.discriminator_A.load_state_dict(\n",
    "            state_dict=checkPoint['model_discriminatorA'])\n",
    "        self.discriminator_B.load_state_dict(\n",
    "            state_dict=checkPoint['model_discriminatorB'])\n",
    "        self.generator_optimizer.load_state_dict(\n",
    "            state_dict=checkPoint['generator_optimizer'])\n",
    "        self.discriminator_optimizer.load_state_dict(\n",
    "            state_dict=checkPoint['discriminator_optimizer'])\n",
    "        epoch = int(checkPoint['epoch']) + 1\n",
    "        self.generator_loss_store = checkPoint['generator_loss_store']\n",
    "        self.discriminator_loss_store = checkPoint['discriminator_loss_store']\n",
    "        return epoch\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Train CycleGAN using source dataset and target dataset\")\n",
    "\n",
    "    logf0s_normalization_default = './cache/logf0s_normalization.npz'\n",
    "    mcep_normalization_default = './cache/mcep_normalization.npz'\n",
    "    coded_sps_A_norm = './cache/coded_sps_A_norm.pickle'\n",
    "    coded_sps_B_norm = './cache/coded_sps_B_norm.pickle'\n",
    "    model_checkpoint = './model_checkpoint/'\n",
    "    resume_training_at = './model_checkpoint/_CycleGAN_CheckPoint'\n",
    "    #     resume_training_at = None\n",
    "\n",
    "    validation_A_dir_default = './data/S0913/'\n",
    "    output_A_dir_default = './converted_sound/S0913'\n",
    "\n",
    "    validation_B_dir_default = './data/gaoxiaosong/'\n",
    "    output_B_dir_default = './converted_sound/gaoxiaosong/'\n",
    "\n",
    "    parser.add_argument('--logf0s_normalization', type=str,\n",
    "                        help=\"Cached location for log f0s normalized\", default=logf0s_normalization_default)\n",
    "    parser.add_argument('--mcep_normalization', type=str,\n",
    "                        help=\"Cached location for mcep normalization\", default=mcep_normalization_default)\n",
    "    parser.add_argument('--coded_sps_A_norm', type=str,\n",
    "                        help=\"mcep norm for data A\", default=coded_sps_A_norm)\n",
    "    parser.add_argument('--coded_sps_B_norm', type=str,\n",
    "                        help=\"mcep norm for data B\", default=coded_sps_B_norm)\n",
    "    parser.add_argument('--model_checkpoint', type=str,\n",
    "                        help=\"location where you want to save the model\", default=model_checkpoint)\n",
    "    parser.add_argument('--resume_training_at', type=str,\n",
    "                        help=\"Location of the pre-trained model to resume training\",\n",
    "                        default=resume_training_at)\n",
    "    parser.add_argument('--validation_A_dir', type=str,\n",
    "                        help=\"validation set for sound source A\", default=validation_A_dir_default)\n",
    "    parser.add_argument('--output_A_dir', type=str,\n",
    "                        help=\"output for converted Sound Source A\", default=output_A_dir_default)\n",
    "    parser.add_argument('--validation_B_dir', type=str,\n",
    "                        help=\"Validation set for sound source B\", default=validation_B_dir_default)\n",
    "    parser.add_argument('--output_B_dir', type=str,\n",
    "                        help=\"Output for converted sound Source B\", default=output_B_dir_default)\n",
    "\n",
    "    argv = parser.parse_args()\n",
    "\n",
    "    logf0s_normalization = argv.logf0s_normalization\n",
    "    mcep_normalization = argv.mcep_normalization\n",
    "    coded_sps_A_norm = argv.coded_sps_A_norm\n",
    "    coded_sps_B_norm = argv.coded_sps_B_norm\n",
    "    model_checkpoint = argv.model_checkpoint\n",
    "    resume_training_at = argv.resume_training_at\n",
    "\n",
    "    validation_A_dir = argv.validation_A_dir\n",
    "    output_A_dir = argv.output_A_dir\n",
    "    validation_B_dir = argv.validation_B_dir\n",
    "    output_B_dir = argv.output_B_dir\n",
    "\n",
    "    # Check whether following cached files exists\n",
    "    if not os.path.exists(logf0s_normalization) or not os.path.exists(mcep_normalization):\n",
    "        print(\n",
    "            \"Cached files do not exist, please run the program preprocess_training.py first\")\n",
    "\n",
    "    cycleGAN = CycleGANTraining(logf0s_normalization=logf0s_normalization,\n",
    "                                mcep_normalization=mcep_normalization,\n",
    "                                coded_sps_A_norm=coded_sps_A_norm,\n",
    "                                coded_sps_B_norm=coded_sps_B_norm,\n",
    "                                model_checkpoint=model_checkpoint,\n",
    "                                validation_A_dir=validation_A_dir,\n",
    "                                output_A_dir=output_A_dir,\n",
    "                                validation_B_dir=validation_B_dir,\n",
    "                                output_B_dir=output_B_dir,\n",
    "                                restart_training_at=resume_training_at)\n",
    "    cycleGAN.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa5a4e99-9aa0-479c-8856-23bab9297855",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainingDataset(Dataset):\n",
    "    def __init__(self, datasetA, datasetB, n_frames=128):\n",
    "        self.datasetA = datasetA\n",
    "        self.datasetB = datasetB\n",
    "        self.n_frames = n_frames\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dataset_A = self.datasetA\n",
    "        dataset_B = self.datasetB\n",
    "        n_frames = self.n_frames\n",
    "\n",
    "        self.length = min(len(dataset_A), len(dataset_B))\n",
    "\n",
    "        num_samples = min(len(dataset_A), len(dataset_B))\n",
    "        train_data_A_idx = np.arange(len(dataset_A))\n",
    "        train_data_B_idx = np.arange(len(dataset_B))\n",
    "        np.random.shuffle(train_data_A_idx)\n",
    "        np.random.shuffle(train_data_B_idx)\n",
    "        train_data_A_idx_subset = train_data_A_idx[:num_samples]\n",
    "        train_data_B_idx_subset = train_data_B_idx[:num_samples]\n",
    "\n",
    "        train_data_A = list()\n",
    "        train_data_B = list()\n",
    "\n",
    "        for idx_A, idx_B in zip(train_data_A_idx_subset, train_data_B_idx_subset):\n",
    "            data_A = dataset_A[idx_A]\n",
    "            frames_A_total = data_A.shape[1]\n",
    "            assert frames_A_total >= n_frames\n",
    "            start_A = np.random.randint(frames_A_total - n_frames + 1)\n",
    "            end_A = start_A + n_frames\n",
    "            train_data_A.append(data_A[:, start_A:end_A])\n",
    "\n",
    "            data_B = dataset_B[idx_B]\n",
    "            frames_B_total = data_B.shape[1]\n",
    "            assert frames_B_total >= n_frames\n",
    "            start_B = np.random.randint(frames_B_total - n_frames + 1)\n",
    "            end_B = start_B + n_frames\n",
    "            train_data_B.append(data_B[:, start_B:end_B])\n",
    "\n",
    "        train_data_A = np.array(train_data_A)\n",
    "        train_data_B = np.array(train_data_B)\n",
    "\n",
    "        return train_data_A[index], train_data_B[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.datasetA), len(self.datasetB))\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     trainA = np.random.randn(162, 24, 554)\n",
    "#     trainB = np.random.randn(158, 24, 554)\n",
    "#     dataset = trainingDataset(trainA, trainB)\n",
    "#     trainLoader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "#                                               batch_size=2,\n",
    "#                                               shuffle=True)\n",
    "#     for epoch in range(10):\n",
    "#         for i, (trainA, trainB) in enumerate(trainLoader):\n",
    "#             print(trainA.shape, trainB.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
